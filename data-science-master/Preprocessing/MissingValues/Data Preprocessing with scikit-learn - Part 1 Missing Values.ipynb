{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing with scikit-learn - Missing Values\n",
    "\n",
    "In this tutorial I illustrate how to preprocess data using [scikit-learn](https://scikit-learn.org/stable/), a Python library for machine learning.\n",
    "\n",
    "Data preprocessing transforms data into a format which is more suitable for estimators. Data preprocessing involves the following operations:\n",
    "* dealing with missing values\n",
    "* normalization\n",
    "* standardization\n",
    "* formatting\n",
    "* binning\n",
    "\n",
    "In my previous articles I illustrated how to deal with [missing values](https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-1-missing-data-45e76b781993), [normalization](https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-3-normalisation-5b5392d27673), [standardization](https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-4-standardization-ccd5b1608f1c), [formatting](https://towardsdatascience.com/data-processing-with-python-pandas-part-2-data-formatting-710c2eafa426) and [binning](https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-5-binning-c5bd5fd1b950) with Python `pandas`. In this tutorial I show you how to deal with mising values with `scikit-learn`. For the other preprocessing techniques in scikit-learn, I will write other posts.\n",
    "\n",
    "All the `scikit-learn` operations described in this tutorial follow the following steps:\n",
    "* select a preprocessing methodology\n",
    "* fit it through the `fit()` function\n",
    "* apply it to data through the `transform()` function.\n",
    "\n",
    "The `scikit-learn` library works only with arrays, thus when performing every operation, a dataframe column must be converted to an array. This can be achieved through the `numpy.array()` function, which receives the dataframe column as input. In addition, the `fit()` function receives as input an array of arrays, each representing a sample of the dataset. Thus the `reshape()` function could be used to convert a standard array to an array of arrays.\n",
    "\n",
    "\n",
    "## Data Import\n",
    "In this tutorial we exploit the `cupcake.csv` dataset, which contains the trend search of the word `cupcake` on Google Trends. Data are extracted from [this link](https://trends.google.com/trends/explore?q=%2Fm%2F03p1r4&date=all). In the original dataset data in correspondence of `2004-02` and `2006-03` have been removed, in order to demonstrate how to deal with missing values. The original values were 5 and 10 respectively. We exploit the `pandas` library to import the dataset and we transform it into a dataframe through the `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mese</th>\n",
       "      <th>Cupcake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mese  Cupcake\n",
       "0  2004-01      5.0\n",
       "1  2004-02      NaN\n",
       "2  2004-03      4.0\n",
       "3  2004-04      6.0\n",
       "4  2004-05      5.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cupcake.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values are values not available in the original dataset. One solution to deal with missing values could be their removal from the dataset. However, this leads to data loss. The `scikit-learn` library provides two [mechanisms to deal with missing values](https://scikit-learn.org/stable/modules/impute.html): \n",
    "* Univariate Feature Imputation\n",
    "* Multivariate Feature Imputation\n",
    "* Nearest neighbors imputation\n",
    "\n",
    "## Univariate Feature Imputation\n",
    "In the Univariate Feature Imputation involves the replacement of missing values with a constant value or some provided statistics related to a feature. The `SimpleImputer` class can be used to perform univariate feature imputation. We specify which is the missing value through the `missing_values` parameter and the replacement strategy through the `strategy` parameter. For example, we can replace all the `NaN` values (identified by the `numpy.nan` variable) with the average value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "preprocessor = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the preprocessor with the `Cupcake` column of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df['Cupcake']).reshape(-1,1)\n",
    "preprocessor.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the `transform()` function to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep = preprocessor.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert it to the original shape by applying the inverse `reshape()` function and we store the result into a new column of the datafram `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mese</th>\n",
       "      <th>Cupcake</th>\n",
       "      <th>Cupcake_univariate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mese  Cupcake  Cupcake_univariate\n",
       "0  2004-01      5.0            5.000000\n",
       "1  2004-02      NaN           50.079208\n",
       "2  2004-03      4.0            4.000000\n",
       "3  2004-04      6.0            6.000000\n",
       "4  2004-05      5.0            5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cupcake_univariate'] = X_prep.reshape(1,-1)[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Feature Imputation\n",
    "In the multivariate feature imputation each feature with missing values is calculated as a function of the other features. An iterative imputation is built thus the maximum number of iteration must be specified. We can use the `IterativeImputer` class. We consider two features: the column `Cupcake` and the index of the dataframe. Since the `IterativeImputer` is still at the experimental stage, we must enable it explicitly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "preprocessor = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert the two features into arrays and transform them in the form `[[f11,f21], [f12,f22] ...]`. This can be done by applying the `reshape()` function to each feature and then the `hstack()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(df['Cupcake']).reshape(-1,1)\n",
    "X2 = np.array(df.index).reshape(-1,1)\n",
    "X = np.hstack((X1,X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the preprocessor with the obtained features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterativeImputer(add_indicator=False, estimator=None,\n",
       "                 imputation_order='ascending', initial_strategy='mean',\n",
       "                 max_iter=10, max_value=None, min_value=None,\n",
       "                 missing_values=nan, n_nearest_features=None, random_state=0,\n",
       "                 sample_posterior=False, skip_complete=False, tol=0.001,\n",
       "                 verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we apply the preprocessor to the same features `X`. In order to retrieve the result of the operation, we must apply the `hsplit()` function, which splits the array horizontally, then we apply the inverse `reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep = preprocessor.transform(X)\n",
    "df['Cupcake_multivariate'] = np.hsplit(X_prep, 2)[0].reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check results. Missing values are located at position 26 and 1. It is interesting to note that the two types of imputation produce different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mese                    2006-03\n",
       "Cupcake                     NaN\n",
       "Cupcake_univariate      50.0792\n",
       "Cupcake_multivariate    28.6311\n",
       "Name: 26, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mese                    2004-02\n",
       "Cupcake                     NaN\n",
       "Cupcake_univariate      50.0792\n",
       "Cupcake_multivariate    21.6101\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors imputation\n",
    "This category of imputation fills missing values using the k-Nearest Neighbors approach. Each missing value is calculated using values from `n_neighbors` nearest neighbors that have a value. We can use the `KNNImputer` class of the `scikit-learn` library. In order to work properly, we must specify at least two features. Thus we exploit the `X` variable, previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "preprocessor = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "preprocessor.fit(X)\n",
    "X_prep = preprocessor.transform(X)\n",
    "df['Cupcake_knn'] = np.hsplit(X_prep, 2)[0].reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mese                    2006-03\n",
       "Cupcake                     NaN\n",
       "Cupcake_univariate      50.0792\n",
       "Cupcake_multivariate    28.6311\n",
       "Cupcake_knn                10.7\n",
       "Name: 26, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mese                    2004-02\n",
       "Cupcake                     NaN\n",
       "Cupcake_univariate      50.0792\n",
       "Cupcake_multivariate    21.6101\n",
       "Cupcake_knn             4.91892\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely, the `KNNImputer` produces the nearest values to those in the original dataset (10 for position 26 and 5 for position 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
